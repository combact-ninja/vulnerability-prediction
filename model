import tensorflow as tf
from tensorflow.keras.layers import Layer, Dense, Activation
from tensorflow.keras import Model
import tensorflow_addons as tfa

# Temporal Graph Attention Layer
class TemporalGraphAttentionLayer(Layer):
    def __init__(self, units):
        super(TemporalGraphAttentionLayer, self).__init__()
        self.units = units
        self.attention = tfa.layers.MultiHeadAttention(num_heads=1, head_size=units)
        self.dense = Dense(units)
    
    def call(self, inputs, adj_matrix, time_encoding):
        # inputs: node features [batch_size, num_nodes, feature_dim]
        # adj_matrix: adjacency matrix [batch_size, num_nodes, num_nodes]
        # time_encoding: time features [batch_size, num_nodes, time_dim]

        # Apply attention mechanism
        attn_output = self.attention([inputs, inputs], adj_matrix)
        # Combine attention output with time encoding
        combined = attn_output + time_encoding
        # Apply dense layer
        output = self.dense(combined)
        return output

# Lightweight Temporal Graph Attention Network
class LTGAT(Model):
    def __init__(self, input_dim, hidden_dim, output_dim, time_dim):
        super(LTGAT, self).__init__()
        self.layer1 = TemporalGraphAttentionLayer(hidden_dim)
        self.layer2 = TemporalGraphAttentionLayer(hidden_dim)
        self.dense_out = Dense(output_dim)
        self.time_dense = Dense(time_dim)
    
    def call(self, inputs, adj_matrix):
        # Create time encoding
        time_encoding = self.time_dense(inputs)
        # Layer 1
        x = self.layer1(inputs, adj_matrix, time_encoding)
        x = Activation('relu')(x)
        # Layer 2
        x = self.layer2(x, adj_matrix, time_encoding)
        x = Activation('relu')(x)
        # Output Layer
        x = self.dense_out(x)
        return x

# Example usage
if __name__ == "__main__":
    # Sample data
    batch_size = 1
    num_nodes = 3
    feature_dim = 4
    hidden_dim = 8
    output_dim = 2
    time_dim = 4

    # Node features: [batch_size, num_nodes, feature_dim]
    node_features = tf.random.uniform((batch_size, num_nodes, feature_dim))

    # Adjacency matrix: [batch_size, num_nodes, num_nodes]
    adj_matrix = tf.constant([[[1, 1, 0], [1, 1, 1], [0, 1, 1]]], dtype=tf.float32)

    # Model
    model = LTGAT(input_dim=feature_dim, hidden_dim=hidden_dim, output_dim=output_dim, time_dim=time_dim)

    # Forward pass
    output = model(node_features, adj_matrix)
    print(output)
