import tensorflow as tf
from tensorflow.keras.layers import Layer, Dense
from tensorflow.keras import Model

class GatedGraphUnit(Layer):
    def __init__(self, units, temporal_units):
        super(GatedGraphUnit, self).__init__()
        self.units = units
        self.temporal_attention = TemporalAttention(temporal_units)
        self.dense_z = Dense(units, activation='sigmoid')
        self.dense_r = Dense(units, activation='sigmoid')
        self.dense_h = Dense(units, activation='tanh')
        self.dense_h_tilde_transform = Dense(units)  # Transform h_tilde to match the dimension of x_temporal

    def call(self, x, adj):
        # x: Node features [batch_size, num_nodes, feature_dim]
        # adj: Adjacency matrix [batch_size, num_nodes, num_nodes]

        # Temporal attention
        x_temporal = self.temporal_attention(x)

        # Update gate
        z = self.dense_z(x_temporal)

        # Reset gate
        r = self.dense_r(x_temporal)

        # Graph attention: Message passing using adjacency matrix
        x_graph = tf.matmul(adj, x)  # [batch_size, num_nodes, feature_dim]

        # Apply a transformation to x_graph to match the shape of r
        x_graph_transformed = Dense(self.units)(x_graph)

        # Element-wise multiplication between r and x_graph_transformed
        r_x = r * x_graph_transformed

        # Candidate hidden state
        h_tilde = self.dense_h(tf.matmul(adj, r_x))

        # Transform h_tilde to match the dimension of x_temporal
        h_tilde_transformed = self.dense_h_tilde_transform(h_tilde)

        # New hidden state
        h = (1 - z) * x_temporal + z * h_tilde_transformed

        return h

class TemporalAttention(Layer):
    def __init__(self, units):
        super(TemporalAttention, self).__init__()
        self.units = units
        self.dense = Dense(units)

    def call(self, x):
        # x: Node features [batch_size, num_nodes, feature_dim]
        # Apply dense layer and return (simulate attention)
        return self.dense(x)

class GatedGraphSequenceNN(Model):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, temporal_units):
        super(GatedGraphSequenceNN, self).__init__()
        self.num_layers = num_layers
        self.ggus = [GatedGraphUnit(hidden_dim, temporal_units) for _ in range(num_layers)]
        self.dense_in = Dense(hidden_dim)
        self.dense_out = Dense(output_dim)

    def call(self, x, adj):
        x = self.dense_in(x)  # Project input to hidden_dim
        for i in range(self.num_layers):
            x = self.ggus[i](x, adj)
        x = tf.reshape(x, (x.shape[0], -1))
        output = self.dense_out(x)
        return output

# Sample data for demonstration
def generate_sample_data(num_samples, num_nodes, feature_dim):
    node_features = tf.random.uniform((num_samples, num_nodes, feature_dim))
    adj_matrix = tf.random.uniform((num_samples, num_nodes, num_nodes))
    labels = tf.random.uniform((num_samples, 2))
    return node_features, adj_matrix, labels

# Hyperparameters
num_samples = 1000
num_nodes = 120
feature_dim = 120
hidden_dim = 64
output_dim = 2
num_layers = 2
epochs = 10
batch_size = 32
temporal_units = 64  # Set to match the hidden_dim

# Model
model = GatedGraphSequenceNN(input_dim=feature_dim, hidden_dim=hidden_dim, output_dim=output_dim,
                             num_layers=num_layers, temporal_units=temporal_units)

# Loss function
loss_object = tf.keras.losses.MeanSquaredError()

# Optimizer
optimizer = tf.keras.optimizers.Adam()

from tqdm import tqdm

def train(model, epochs, batch_size, num_samples, num_nodes, feature_dim):
    for epoch in range(epochs):
        epoch_loss_avg = tf.keras.metrics.Mean()
        progress_bar = tqdm(range(num_samples // batch_size), desc=f'Epoch {epoch + 1}', ascii=True)
        for i in progress_bar:
            node_features, adj_matrix, labels = generate_sample_data(batch_size, num_nodes, feature_dim)
            with tf.GradientTape() as tape:
                predictions = model(node_features, adj_matrix)
                loss = loss_object(labels, predictions)
            gradients = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))
            epoch_loss_avg.update_state(loss)
            progress_bar.set_postfix({'loss': loss.numpy()}, refresh=False)
        progress_bar.close()
        print(f'Epoch {epoch + 1}, Loss: {epoch_loss_avg.result().numpy()}')

# Training with loading arrow
train(model, epochs, batch_size, num_samples, num_nodes, feature_dim)

# def train(model, epochs, batch_size, num_samples, num_nodes, feature_dim, verbose=True):
#     for epoch in range(epochs):
#         epoch_loss_avg = tf.keras.metrics.Mean()
#         for i in range(num_samples // batch_size):
#             node_features, adj_matrix, labels = generate_sample_data(batch_size, num_nodes, feature_dim)
#             with tf.GradientTape() as tape:
#                 predictions = model(node_features, adj_matrix)
#                 loss = loss_object(labels, predictions)
#             gradients = tape.gradient(loss, model.trainable_variables)
#             optimizer.apply_gradients(zip(gradients, model.trainable_variables))
#             epoch_loss_avg.update_state(loss)
#
#         if verbose:
#             print(f'Epoch {epoch + 1}, Loss: {epoch_loss_avg.result().numpy()}')
#
#
# # Training with verbose
# train(model, epochs, batch_size, num_samples, num_nodes, feature_dim, verbose=True)


