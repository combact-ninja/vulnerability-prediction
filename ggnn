import tensorflow as tf
from tensorflow.keras import layers, Model, optimizers, losses, metrics
import numpy as np
from sklearn.model_selection import train_test_split

class GatedPropagation(layers.Layer):
    def __init__(self, hidden_dim, n_node, n_edge):
        super(GatedPropagation, self).__init__()
        self.hidden_dim = hidden_dim
        self.n_node = n_node
        self.n_edge = n_edge

        self.gate_r = layers.Dense(hidden_dim)
        self.gate_z = layers.Dense(hidden_dim)
        self.trans = layers.Dense(hidden_dim)

    def call(self, x_in, x_out, x_curt, matrix):
        matrix_in = matrix[:, :, :self.n_node * self.n_edge]
        matrix_out = matrix[:, :, self.n_node * self.n_edge:]

        a_in = tf.matmul(matrix_in, x_in)
        a_out = tf.matmul(matrix_out, x_out)
        a = tf.concat([a_in, a_out, x_curt], axis=-1)

        z = tf.sigmoid(self.gate_z(a))
        r = tf.sigmoid(self.gate_r(a))

        joint_input = tf.concat([a_in, a_out, r * x_curt], axis=-1)
        h_hat = tf.tanh(self.trans(joint_input))
        output = (1 - z) * x_curt + z * h_hat

        return output

class GraphFeature(layers.Layer):
    def __init__(self, hidden_dim, n_node, n_anno):
        super(GraphFeature, self).__init__()
        self.hidden_dim = hidden_dim
        self.fc_i = layers.Dense(hidden_dim)
        self.fc_j = layers.Dense(hidden_dim)

    def call(self, x):
        x_sigm = tf.sigmoid(self.fc_i(x))
        x_tanh = tf.tanh(self.fc_j(x))
        x_new = tf.reduce_sum(x_sigm * x_tanh, axis=1)
        return tf.tanh(x_new)

class GGNN(Model):
    def __init__(self, hidden_dim, n_node, n_edge, n_steps, annotation_dim, n_output):
        super(GGNN, self).__init__()
        self.hidden_dim = hidden_dim
        self.n_node = n_node
        self.n_edge = n_edge
        self.n_steps = n_steps
        self.annotation_dim = annotation_dim

        self.fc_in = layers.Dense(hidden_dim * n_edge)
        self.fc_out = layers.Dense(hidden_dim * n_edge)
        self.gated_update = GatedPropagation(hidden_dim, n_node, n_edge)
        self.graph_aggregate = GraphFeature(hidden_dim, n_node, annotation_dim)
        self.fc_output = layers.Dense(n_output)

    def call(self, inputs):
        x, a, m = inputs
        all_x = []
        for _ in range(self.n_steps):
            in_states = self.fc_in(x)
            out_states = self.fc_out(x)
            in_states = tf.reshape(in_states, [-1, self.n_node, self.hidden_dim, self.n_edge])
            out_states = tf.reshape(out_states, [-1, self.n_node, self.hidden_dim, self.n_edge])
            in_states = tf.transpose(in_states, perm=[0, 1, 3, 2])
            out_states = tf.transpose(out_states, perm=[0, 1, 3, 2])
            in_states = tf.reshape(in_states, [-1, self.n_node * self.n_edge, self.hidden_dim])
            out_states = tf.reshape(out_states, [-1, self.n_node * self.n_edge, self.hidden_dim])
            x = self.gated_update(in_states, out_states, x, m)
            all_x.append(x)

        output = self.graph_aggregate(tf.concat([x, a], axis=-1))
        output = self.fc_output(output)
        return output
# Preprocessing Function
def preprocess_data(features, labels):
    # Convert features and labels to tensors
    features = tf.convert_to_tensor(features, dtype=tf.float32)
    labels = tf.convert_to_tensor(labels, dtype=tf.int32)
    
    # Convert each input vector to graph nodes, edges, and adjacency matrix
    nodes = features
    n_samples, n_features = features.shape
    adj_matrices = tf.ones((n_samples, n_features, n_features), dtype=tf.float32)  # Simple full adjacency
    annotations = tf.ones((n_samples, n_features, 1), dtype=tf.float32)  # Dummy annotations for each node
    labels = tf.expand_dims(labels, axis=-1)
    
    return nodes, annotations, adj_matrices, labels




features = np.random.rand(2000, 120).astype(np.float32)
labels = np.random.randint(0, 2, 2000).astype(np.int32)
x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)


nodes_train, annotations_train, adj_matrices_train, labels_train = preprocess_data(x_train, y_train)
nodes_test, annotations_test, adj_matrices_test, labels_test = preprocess_data(x_test, y_test)

hidden_dim = 64
n_node = 120
n_edge = 1
n_steps = 5
annotation_dim = 1
n_output = 2

ggnn = GGNN(hidden_dim, n_node, n_edge, n_steps, annotation_dim, n_output)

ggnn.compile(optimizer=optimizers.Adam(learning_rate=0.001),
             loss=losses.SparseCategoricalCrossentropy(from_logits=True),
             metrics=[metrics.SparseCategoricalAccuracy()])

history = ggnn.fit((nodes_train, annotations_train, adj_matrices_train), labels_train, epochs=10, batch_size=32, validation_split=0.2)

